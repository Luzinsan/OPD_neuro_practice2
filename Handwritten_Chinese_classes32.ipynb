{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Handwritten Chinese v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luzinsan/OPD_neuro_practice2/blob/main/Handwritten_Chinese_classes32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HlCG5i4kDnS"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "!git clone https://github.com/AI-FREE-Team/Traditional-Chinese-Handwriting-Dataset.git\n",
        "OutputFolder = '/content/Handwritten_Data'\n",
        "!rm -rf '/content/Handwritten_Data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIMzxCtACUxL"
      },
      "source": [
        "SIZE = 32 # рассматриваем 32 класса"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEsfKRwc_bg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f33560-3d80-449b-d5e1-3999aba0da48"
      },
      "source": [
        "CompressedFiles = []\n",
        "\n",
        "os.chdir('/content/Traditional-Chinese-Handwriting-Dataset/data')\n",
        "\n",
        "for item in os.listdir():  \n",
        "  if item.endswith('.zip'): # Check for \".zip\" extension.\n",
        "    file_path = os.path.abspath(item) # Get full path of the compressed file. \n",
        "    CompressedFiles.append(file_path)\n",
        "\n",
        "for file in CompressedFiles:     \n",
        "  # Construct a ZipFile object with the filename, and then extract it.\n",
        "  zip_ref = zipfile.ZipFile(file).extractall(OutputFolder) \n",
        "  \n",
        "  source_path = OutputFolder + '/cleaned_data(50_50)'\n",
        "  img_list = os.listdir(source_path)\n",
        "\n",
        "  for img in img_list:\n",
        "      shutil.move(source_path + '/' + img, OutputFolder) # Move a file to another location. \n",
        "  \n",
        "  shutil.rmtree(OutputFolder + '/cleaned_data(50_50)') \n",
        "  #print(f'Decompress successfully {file} ......')\n",
        "  #print( 'Moving images according to traditional Chinese characters......' )\n",
        "\n",
        "ImageList = os.listdir(OutputFolder)\n",
        "ImageList = [img for img in ImageList if len(img)>1]\n",
        "WordList = list(set([w.split('_')[0] for w in ImageList]))[:SIZE]\n",
        "\n",
        "for w in WordList:\n",
        "  try:\n",
        "    os.chdir(OutputFolder) # Change the current working directory to OutputPath.\n",
        "    os.mkdir(w) # Create the new word folder in OutputPath.\n",
        "    MoveList = [img for img in ImageList if w in img]\n",
        "                \n",
        "  except: \n",
        "    os.chdir(OutputFolder)\n",
        "    MoveList = [img for img in ImageList if w in img ]\n",
        "  \n",
        "  finally:            \n",
        "    for img in MoveList:\n",
        "      old_path = OutputFolder + '/' + img\n",
        "      new_path = OutputFolder + '/' + w + '/' + img\n",
        "      shutil.move( old_path, new_path )\n",
        "\n",
        "#print( 'Data Deployment completed.' )"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decompress successfully /content/Traditional-Chinese-Handwriting-Dataset/data/cleaned_data(50_50)-20200420T071507Z-001.zip ......\n",
            "Moving images according to traditional Chinese characters......\n",
            "Decompress successfully /content/Traditional-Chinese-Handwriting-Dataset/data/cleaned_data(50_50)-20200420T071507Z-003.zip ......\n",
            "Moving images according to traditional Chinese characters......\n",
            "Decompress successfully /content/Traditional-Chinese-Handwriting-Dataset/data/cleaned_data(50_50)-20200420T071507Z-004.zip ......\n",
            "Moving images according to traditional Chinese characters......\n",
            "Decompress successfully /content/Traditional-Chinese-Handwriting-Dataset/data/cleaned_data(50_50)-20200420T071507Z-002.zip ......\n",
            "Moving images according to traditional Chinese characters......\n",
            "Data Deployment completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtJidZSSed2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e603dbc1-9466-40d2-89be-bf10b7493183"
      },
      "source": [
        "a=0\n",
        "b=0\n",
        "\n",
        "for item in os.listdir(OutputFolder):\n",
        "  if (os.path.isdir(item)):  \n",
        "    a += 1\n",
        "    for i in os.listdir(OutputFolder + '/' + item):\n",
        "      b +=1\n",
        "\n",
        "#print ('Всего: ' + str(a) + ' слов (папка) / Всего: ' + str(b) + ' образцов')\n",
        "#print ('В среднем каждое слово содержит: ' + str (b / a) + ' образцов')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Всего: 32 слов (папка) / Всего: 1675 образцов\n",
            "В среднем каждое слово содержит: 52.34375 образцов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BZsXzH5dSZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0673c7-748b-44b4-ed26-d4df184738b6"
      },
      "source": [
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.1)\n",
        "train_dataset = image_generator.flow_from_directory(str(OutputFolder), class_mode='sparse', batch_size=5, target_size=(50, 50), subset='training')\n",
        "valid_dataset = image_generator.flow_from_directory(str(OutputFolder), class_mode='sparse', batch_size=5, target_size=(50, 50), subset='validation')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1516 images belonging to 32 classes.\n",
            "Found 159 images belonging to 32 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5yTllMEdfrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39accb58-044d-49fb-a939-035ea0a6c8f3"
      },
      "source": [
        "for image_b, label_b in train_dataset:\n",
        "  #print(\"Image batch shape: \", image_b.shape)\n",
        "  #print(\"Label batch shape: \", label_b.shape)\n",
        "  image_batch = image_b\n",
        "  label_batch = label_b\n",
        "  #print(label_batch)\n",
        "  break"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image batch shape:  (5, 50, 50, 3)\n",
            "Label batch shape:  (5,)\n",
            "[14.  1. 29. 22.  8.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WucSLXxZdpuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3132f229-89bd-4cd9-8008-4e1052c80358"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters=16,  kernel_size=3, activation='relu', padding= 'same' , input_shape=(50,50,3)),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
        "  tf.keras.layers.Conv2D(filters=32,  kernel_size=3, activation='relu', padding= 'same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
        "  tf.keras.layers.Conv2D(filters=64,  kernel_size=3, activation='relu', padding= 'same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
        "  tf.keras.layers.Conv2D(filters=128,  kernel_size=3, activation='relu', padding= 'same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(SIZE, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 50, 50, 16)        448       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 25, 25, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 25, 25, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 12, 12, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 12, 12, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 6, 6, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 6, 6, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 3, 3, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 256)               295168    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 32)                8224      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 400,832\n",
            "Trainable params: 400,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWAuDixXdzYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12087daa-6005-4b3d-dfc4-66a4e27f2a90"
      },
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adadelta(learning_rate = 0.9),\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "EPOCHS = 10\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data=valid_dataset,\n",
        "                    epochs=EPOCHS)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "304/304 [==============================] - 10s 30ms/step - loss: 4.9897 - accuracy: 0.0336 - val_loss: 3.5021 - val_accuracy: 0.0189\n",
            "Epoch 2/10\n",
            "304/304 [==============================] - 7s 24ms/step - loss: 3.5064 - accuracy: 0.0323 - val_loss: 3.4621 - val_accuracy: 0.0377\n",
            "Epoch 3/10\n",
            "304/304 [==============================] - 7s 24ms/step - loss: 3.4759 - accuracy: 0.0402 - val_loss: 3.4185 - val_accuracy: 0.0503\n",
            "Epoch 4/10\n",
            "304/304 [==============================] - 7s 24ms/step - loss: 3.4190 - accuracy: 0.0699 - val_loss: 3.3229 - val_accuracy: 0.0943\n",
            "Epoch 5/10\n",
            "304/304 [==============================] - 7s 24ms/step - loss: 3.3169 - accuracy: 0.0838 - val_loss: 3.2197 - val_accuracy: 0.1069\n",
            "Epoch 6/10\n",
            "304/304 [==============================] - 7s 24ms/step - loss: 3.1562 - accuracy: 0.1187 - val_loss: 2.8928 - val_accuracy: 0.1635\n",
            "Epoch 7/10\n",
            "304/304 [==============================] - 7s 24ms/step - loss: 2.8610 - accuracy: 0.1992 - val_loss: 2.7375 - val_accuracy: 0.2075\n",
            "Epoch 8/10\n",
            "304/304 [==============================] - 7s 24ms/step - loss: 2.5171 - accuracy: 0.2698 - val_loss: 2.2128 - val_accuracy: 0.3208\n",
            "Epoch 9/10\n",
            "304/304 [==============================] - 7s 24ms/step - loss: 2.1256 - accuracy: 0.3661 - val_loss: 2.0453 - val_accuracy: 0.4151\n",
            "Epoch 10/10\n",
            "304/304 [==============================] - 8s 25ms/step - loss: 1.8232 - accuracy: 0.4453 - val_loss: 1.7381 - val_accuracy: 0.4906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iyt3xUVf2n_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f25949f-805e-4bf0-8462-701fed8d1a65"
      },
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adadelta(learning_rate = 0.001),\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data=valid_dataset,\n",
        "                    epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "304/304 [==============================] - 9s 26ms/step - loss: 1.4834 - accuracy: 0.5389 - val_loss: 1.6500 - val_accuracy: 0.5094\n",
            "Epoch 2/100\n",
            "304/304 [==============================] - 8s 26ms/step - loss: 1.3689 - accuracy: 0.5679 - val_loss: 1.6114 - val_accuracy: 0.5157\n",
            "Epoch 3/100\n",
            "304/304 [==============================] - 8s 25ms/step - loss: 1.3570 - accuracy: 0.5706 - val_loss: 1.5873 - val_accuracy: 0.5220\n",
            "Epoch 4/100\n",
            "304/304 [==============================] - 8s 26ms/step - loss: 1.2977 - accuracy: 0.5956 - val_loss: 1.5694 - val_accuracy: 0.5283\n",
            "Epoch 5/100\n",
            "304/304 [==============================] - 8s 25ms/step - loss: 1.3127 - accuracy: 0.5930 - val_loss: 1.5561 - val_accuracy: 0.5283\n",
            "Epoch 6/100\n",
            "304/304 [==============================] - 8s 25ms/step - loss: 1.2924 - accuracy: 0.5937 - val_loss: 1.5437 - val_accuracy: 0.5409\n",
            "Epoch 7/100\n",
            "304/304 [==============================] - 8s 25ms/step - loss: 1.2938 - accuracy: 0.5891 - val_loss: 1.5335 - val_accuracy: 0.5409\n",
            "Epoch 8/100\n",
            "304/304 [==============================] - 8s 25ms/step - loss: 1.2848 - accuracy: 0.6003 - val_loss: 1.5243 - val_accuracy: 0.5409\n",
            "Epoch 9/100\n",
            "304/304 [==============================] - 8s 25ms/step - loss: 1.2685 - accuracy: 0.5983 - val_loss: 1.5160 - val_accuracy: 0.5472\n",
            "Epoch 10/100\n",
            "304/304 [==============================] - 8s 25ms/step - loss: 1.2644 - accuracy: 0.5937 - val_loss: 1.5085 - val_accuracy: 0.5472\n",
            "Epoch 11/100\n",
            "249/304 [=======================>......] - ETA: 1s - loss: 1.2437 - accuracy: 0.6164"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEVSZ40id6DC"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([min(plt.ylim()),max(plt.ylim())])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}